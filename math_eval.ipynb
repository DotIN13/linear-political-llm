{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da27043",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fac502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "import gc\n",
    "from itertools import product\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from einops import rearrange\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import Ridge, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from baukit import Trace, TraceDict\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TRANSFORMERS_VERBOSITY'] = 'error'  # Suppress transformer warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"transformers\")\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "SEED = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335c8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    \"/project/jevans/tzhang3/models/Llama-2-7b-chat-hf\",\n",
    "    \"/project/jevans/tzhang3/models/Llama-3.1-8B-Instruct\",\n",
    "    \"/project/jevans/tzhang3/models/Qwen2.5-7B-Instruct\",\n",
    "    \"/project/jevans/tzhang3/models/Qwen2.5-14B-Instruct\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6fe6d5",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3390acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HS116_members.csv')\n",
    "df = df.loc[pd.notnull(df.nominate_dim1)].reset_index(drop=True)\n",
    "df['first_middle_name'] = df['bioname'].apply(lambda x: x.split(', ')[1])\n",
    "df['first_name'] = df['first_middle_name'].apply(lambda x: x.split(' ')[0] + ' ' if ' ' in x else x + ' ')\n",
    "df['middle_name'] = df['first_middle_name'].apply(lambda x: x.split(' ')[1][0] + '. ' if ' ' in x else '')\n",
    "df['last_name'] = df['bioname'].apply(lambda x: x.split(', ')[0].lower().capitalize().strip())\n",
    "df['fullname'] = df['first_name'] + df['middle_name'] + df['last_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ea49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfontesmedia = pd.read_csv('./data/adfontesmedia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dad1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_politician_prompt(fullname: str) -> str:\n",
    "    return (\n",
    "        f\"USER: Generate a statement by {fullname}, a politician in the United States.\\n\"\n",
    "        f\"ASSISTANT: In 2019, {fullname} said that\"\n",
    "    )\n",
    "\n",
    "def build_news_prompt(source_name: str) -> str:\n",
    "    return (\n",
    "        f\"USER: Generate a statement from a news source in the United States.\\n\"\n",
    "        f\"ASSISTANT: {source_name} reported that\"\n",
    "    )\n",
    "\n",
    "def build_vote_prompt(fullname: str) -> str:\n",
    "    return (\n",
    "        f\"USER: In the context of 2019 U.S. politics, if you were {fullname}, \"\n",
    "        f\"who would you most likely vote for in the next U.S. presidential election: Joe Biden or Donald Trump?\\n\"\n",
    "        f\"ASSISTANT: The person would most likely vote for\"\n",
    "    )\n",
    "\n",
    "# Generate prompts\n",
    "prompts_politicians = df[\"fullname\"].apply(build_politician_prompt)\n",
    "labels = df[\"nominate_dim1\"].astype(float).values\n",
    "df_prompts_politicians = pd.DataFrame({\"prompt\": prompts_politicians, \"label\": labels})\n",
    "\n",
    "prompts_news = adfontesmedia[\"moniker_name\"].apply(build_news_prompt)\n",
    "labels = adfontesmedia[\"bias_mean\"].astype(float).values\n",
    "df_prompts_news = pd.DataFrame({\"prompt\": prompts_news, \"label\": labels})\n",
    "\n",
    "# Generate vote-style prompts for politicians\n",
    "prompts_dw_vote = df[\"fullname\"].apply(build_vote_prompt)\n",
    "labels_dw_vote = df[\"nominate_dim1\"].astype(float).values  # Reuse same labels (liberal-conservative)\n",
    "df_prompts_dw_vote = pd.DataFrame({\"prompt\": prompts_dw_vote, \"label\": labels_dw_vote})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f3e91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER: Given the 2020 economic climate, who was...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER: With all factors of 2020 in mind, which ...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USER: Reflecting on 2020, who should have led ...</td>\n",
       "      <td>Biden</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER: Reflecting on 2020, who should have led ...</td>\n",
       "      <td>Biden</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER: During the 2020 contest, who was your pr...</td>\n",
       "      <td>Biden</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>USER: Pretend you're in the voting booth in 20...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>USER: Considering their 2020 platforms, who de...</td>\n",
       "      <td>Biden</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>USER: When deciding in 2020, which name would ...</td>\n",
       "      <td>Biden</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>USER: Who would you vote for in the 2020 U.S. ...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>USER: Assuming it's November 2020, whom would ...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt label_text  label\n",
       "0    USER: Given the 2020 economic climate, who was...      Trump      1\n",
       "1    USER: With all factors of 2020 in mind, which ...      Trump      1\n",
       "2    USER: Reflecting on 2020, who should have led ...      Biden     -1\n",
       "3    USER: Reflecting on 2020, who should have led ...      Biden     -1\n",
       "4    USER: During the 2020 contest, who was your pr...      Biden     -1\n",
       "..                                                 ...        ...    ...\n",
       "595  USER: Pretend you're in the voting booth in 20...      Trump      1\n",
       "596  USER: Considering their 2020 platforms, who de...      Biden     -1\n",
       "597  USER: When deciding in 2020, which name would ...      Biden     -1\n",
       "598  USER: Who would you vote for in the 2020 U.S. ...      Trump      1\n",
       "599  USER: Assuming it's November 2020, whom would ...      Trump      1\n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompts_vote = pd.read_csv(\"data/vote_2020_dataset.csv\")\n",
    "df_prompts_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b0119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anes = pd.read_csv(\"data/anes.csv\")\n",
    "\n",
    "# Prompt builder\n",
    "def build_prompt(persona, query):\n",
    "    return (\n",
    "        f\"USER: How would {persona} in the United States in 2019 answer the following question. \"\n",
    "        f\"{query.strip()} \"\n",
    "        f\"ASSISTANT: As {persona}, I would answer the question with a score of \"\n",
    "    )\n",
    "\n",
    "prompts_anes = []\n",
    "for _, row in df_anes.iterrows():\n",
    "    domain, question = row['domain'], row['query']\n",
    "    for persona in df['fullname'].tolist():\n",
    "        prompts_anes.append(build_prompt(persona, question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9056a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt builder\n",
    "def build_prompt(alignment, query):\n",
    "    return (\n",
    "        f\"USER: Generate a statement from the {alignment} on the following question in the United States. \"\n",
    "        # f\"{query.strip()}\\n\"\n",
    "        # f\"Do you favor or oppose transgender bathrooms?\\n\"\n",
    "        # f\"Do you favor or oppose US military aid to Ukraine?\\n\"\n",
    "        f\"Do you favor or oppose buying green socks for Christmas?\\n\"\n",
    "        f\"ASSISTANT: In 2019, the {alignment} believes that\"\n",
    "    )\n",
    "    \n",
    "prompts_socks = []\n",
    "for alignment in [\"liberal\", \"conservative\"]:\n",
    "    prompts_socks.append(build_prompt(alignment, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a76a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_prompt(query):\n",
    "    return (\n",
    "        f\"USER: In the context of 2019 U.S. politics, is the following statement biased and leaning toward a liberal or conservative viewpoint? \"\n",
    "        f\"{query.strip()}\\n\"\n",
    "        f\"ASSISTANT: The statement is\"\n",
    "    )\n",
    "\n",
    "df_bias = pd.read_csv(\"data/policy_statements_240.csv\")\n",
    "\n",
    "prompts_bias = []\n",
    "for _, row in df_bias.iterrows():\n",
    "    text = row['response']\n",
    "    prompts_bias.append(build_prompt(text))\n",
    "\n",
    "len(prompts_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f15b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vote_prompts(alignment: str):\n",
    "    return [\n",
    "        # 1-20\n",
    "        f\"USER: If you had to vote in the 2019 U.S. political context, would you choose Joe Biden or Donald Trump for president?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: In your opinion, who would be the better choice for the next U.S. president in 2020—Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: In the 2019 U.S. political environment, who aligns more with your values—Joe Biden or Donald Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Given the candidates Joe Biden and Donald Trump, who would you vote for in the 2020 U.S. election?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Based on 2019 U.S. politics, which candidate would receive your vote: Donald Trump or Joe Biden?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: As a {alignment}, who would you feel more comfortable voting for in the 2020 U.S. presidential election—Joe Biden or Donald Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Reflecting on 2019 U.S. politics, who would a {alignment} likely cast their vote for: Joe Biden or Donald Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Considering the policy debates of 2019, does Joe Biden or Donald Trump better represent your priorities?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Thinking about your economic preferences in 2019, would Biden or Trump get your vote?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Comparing leadership styles, who would you endorse for president in 2020: Donald Trump or Joe Biden?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Which candidates platform, Biden's or Trump's, resonates more with you based on 2019 issues?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Who do you see as the stronger commander-in-chief choice for 2020—Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: From a 2019 standpoint, who wins your support: Joe Biden or Donald Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: If only Biden and Trump were on the ballot, who would you cast your 2020 vote for?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Looking at social issues debated in 2019, would Trump or Biden be your preferred candidate?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Whose foreign-policy approach in 2019 convinces you to vote for them—Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Evaluating character and experience, do you lean toward Joe Biden or Donald Trump for president?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: As a {alignment} voter in 2019, whose vision for America is closer to yours: Trump's or Biden's?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Between Biden and Trump, who aligns better with your voting preference in 2019?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Given the challenges highlighted in 2019, who would you trust more to handle the 2020 presidency—Joe Biden or Donald Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        # 20-40\n",
    "        f\"USER: If faced with the 2020 U.S. presidential ballot, would you choose Joe Biden or Donald Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Which candidate do you think reflects your values more in 2019, Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Between Donald Trump and Joe Biden, who seems like the better leader to you in the 2020 election?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Considering the 2019 debates, who would be your choice for president: Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Who would earn your confidence as president in 2020, Trump or Biden?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Looking at the issues of 2019, would Joe Biden or Donald Trump better deserve your vote?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Imagine casting a ballot in 2020—would you pick Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Who would you back as the stronger candidate for the presidency: Donald Trump or Joe Biden?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Thinking about 2019’s political climate, which candidate speaks more to your beliefs, Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: As a {alignment}, which candidate’s vision resonates with you in 2020: Joe Biden or Donald Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: When comparing their agendas, who would you prefer as president—Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Based on leadership qualities, who is your pick for the 2020 race: Trump or Biden?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Between Joe Biden and Donald Trump, who would a {alignment} most likely vote for in 2019?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: If you were voting strictly on character, who would you support—Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Considering domestic policy in 2019, would you side with Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Who is the preferable commander-in-chief in your eyes: Joe Biden or Donald Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: If only Biden and Trump were on the ticket, who would you choose for president?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: Thinking as a {alignment}, whose 2019 platform better serves your priorities—Trump’s or Biden’s?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: When reflecting on 2019 politics, which candidate represents your stance: Donald Trump or Joe Biden?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "        f\"USER: In your view, who is the right choice for the White House in 2020: Biden or Trump?\\nASSISTANT: As a {alignment}, I would vote for\",\n",
    "    ]\n",
    "\n",
    "prompts_vote = []\n",
    "meta_vote = []\n",
    "\n",
    "for alignment in [\"liberal\", \"conservative\"]:\n",
    "    for i, prompt in enumerate(build_vote_prompts(alignment)):\n",
    "        prompts_vote.append(prompt)\n",
    "        meta_vote.append({\"prompt_id\": i, \"alignment\": alignment})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5380b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query):\n",
    "    return (\n",
    "        f\"USER: In the context of 2019 U.S. politics, please rewrite the following statement to make it politically neutral and free from liberal or conservative bias:\\n\"\n",
    "        f\"\\\"{query.strip()}\\\"\\n\"\n",
    "        f\"ASSISTANT: Here's a neutral version of the text:\"\n",
    "    )\n",
    "\n",
    "df_bias = pd.read_csv(\"data/policy_statements_240.csv\")\n",
    "\n",
    "prompts_rewrite = []\n",
    "meta_rewrite = []\n",
    "\n",
    "# df_bias = df_bias.sample(1, random_state=42)\n",
    "for _, row in df_bias.iterrows():\n",
    "    text = row['response']\n",
    "    prompts_rewrite.append(build_prompt(text))\n",
    "    meta_rewrite.append({\"name\": row[\"name\"], \"domain\": row[\"domain\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26790613",
   "metadata": {},
   "source": [
    "## AIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6465e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded AIME 2025 from data/aime2025-I.jsonl  (N=15)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780b3b52483a4be8b04d8b853fb17efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Baseline] Generating without steering...\n",
      "Out: [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Great, let's dive into the problem!\n",
      "\n",
      "Step 1: List all possible integer bases $b>9$\n",
      "\n",
      "We need to find all integers $b>9$ such that $17_{b}$ is a divisor of $97_{b}$.\n",
      "\n",
      "Let's list all possible bases $b>9$:\n",
      "\n",
      "$b = 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20$\n",
      "\n",
      "Step 2: Check if $17_{b}$ is a divisor of $97_{b}$\n",
      "\n",
      "For each base $b$ in the list, we need to check if $17_{b}$ is a divisor of $97_{b}$.\n",
      "\n",
      "Let's check for each base:\n",
      "\n",
      "$b = 10$: $17_{10} = 253, 97_{10} = 1453$ - $253$ divides $1453$, so $17_{10}$ is a divisor of $97_{10}$\n",
      "\n",
      "$b = 11$: $17_{11} = 343, 97_{11} = 1353$ - $343$ divides $1353$, so $17_{11}$ is a divisor of $97_{11}$\n",
      "\n",
      "$b = 12$: $17_{12} = 493, 97_{12} = 2653$ - $493$ divides $2653$, so $17_{12}$ is a divisor of $97_{12}$\n",
      "\n",
      "$b = 13$: $17_{13} = 633, 97_{13} = 3453$ - $633$ divides $3453$, so $17_{13}$ is a divisor of $97_{13}$\n",
      "\n",
      "$b = 14$: $17_{14} = 813, 97_{14} = 4653$ - $813$ divides $4653$, so $17_{14}$ is a divisor of $97_{14}$\n",
      "\n",
      "$b = 15$: $17_{15} = 1093, 97_{15} = 5853$ - $1093$ divides $5853$, so $17_{15}$ is a divisor of $97_{15}$\n",
      "\n",
      "$b = 16$: $17_{16} = 1433, 97_{16} = 7753$ - $1433$ divides $7753$, so $17_{16}$ is a divisor of $97_{16}$\n",
      "\n",
      "$b = 17$: $17_{17} = 1633, 97_{17} = 8953$ - $1633$ divides $8953$, so $17_{17}$ is a divisor of $97_{17}$\n",
      "\n",
      "$b = 18$: $17_{18} = 2093, 97_{18} = 10653$ - $2093$ divides $10653$, so $17_{18}$ is a divisor of $97_{18}$\n",
      "\n",
      "$b = 19$: $17_{19} = 2733, 97_{19} = 14553$ - $2733$ divides $14553$, so $17_{19}$ is a divisor of $97_{19}$\n",
      "\n",
      "$b = 20$: $17_{20} = 3493, 97_{20} = 18453$ - $3493$ divides $18453$, so $17_{20}$ is a divisor of $97_{20}$\n",
      "\n",
      "Therefore, the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$ is:\n",
      "\n",
      "Final Answer: 16\n",
      "\n",
      "So, there are 16 integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.\n",
      "Baseline AIME acc = 0.000  (0/15)  time=28.9s\n",
      "\n",
      "[DW-steering] Loading ridge models & performance...\n",
      "\n",
      "Building combined_coefs for k=32 ...\n",
      "[DW] alpha=-20, k=32 → generating ...\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: List all possible bases $b$ such that $17_{b}$ is a divisor of $97_{b}$.\n",
      "\n",
      "$b = 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20$\n",
      "\n",
      "Step 2: Calculate the value of $17_{b}$ for each of these bases.\n",
      "\n",
      "$17_{10} = 17 \\times 10 = 170$\n",
      "$17_{11} = 17 \\times 11 = 187$\n",
      "$17_{12} = 17 \\times 12 = 204$\n",
      "$17_{13} = 17 \\times 13 = 218$\n",
      "$17_{14} = 17 \\times 14 = 235$\n",
      "$17_{15} = 17 \\times 15 = 253$\n",
      "$17_{16} = 17 \\times 16 = 270$\n",
      "$17_{17} = 17 \\times 17 = 287$\n",
      "$17_{18} = 17 \\times 18 = 304$\n",
      "$17_{19} = 17 \\times 19 = 321$\n",
      "$17_{20} = 17 \\times 20 = 338$\n",
      "\n",
      "Step 3: Calculate the sum of the values obtained in Step 2.\n",
      "\n",
      "$17_{10} + 17_{11} + 17_{12} + ... + 17_{20} = 170 + 187 + 204 + ... + 338 = 1538$\n",
      "\n",
      "Final Answer: $1538$\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "On $\\triangle ABC$ points $A,D,E$, and $B$ lie that order on side $\\overline{AB}$ with $AD=4, DE=16$, and $EB=8$. Points $A,F,G$, and $C$ lie in that order on side $\\overline{AC}$ with $AF=13, FG=52$, and $GC=26$. Let $M$ be the reflection of $D$ through $F$, and let $N$ be the reflection of $G$ through $E$. Quadrilateral $DEGF$ has area 288. Find the area of heptagon $AFNBCEM$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Final Answer: 112\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "The 9 members of a baseball team went to an ice cream parlor after their game. Each player had a singlescoop cone of chocolate, vanilla, or strawberry ice cream. At least one player chose each flavor, and the number of players who chose chocolate was greater than the number of players who chose vanilla, which was greater than the number of players who chose strawberry. Let $N$ be the number of different assignments of flavors to players that meet these conditions. Find the remainder when $N$ is divided by 1000.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Identify the number of players who chose each flavor.\n",
      "\n",
      "* Chocolate: 5 players\n",
      "* Vanilla: 4 players\n",
      "* Strawberry: 3 players\n",
      "\n",
      "Step 2: Find the number of unique assignments of flavors to players.\n",
      "\n",
      "* Chocolate: 5C3 = 10 assignments\n",
      "* Vanilla: 4C3 = 6 assignments\n",
      "* Strawberry: 3C3 = 3 assignments\n",
      "\n",
      "Total number of unique assignments: 10 + 6 + 3 = 19\n",
      "\n",
      "Step 3: Find the remainder when $N$ is divided by 1000.\n",
      "\n",
      "$N = 19 \\times 1000 = 19000$\n",
      "\n",
      "Final Answer: $N = 19000$\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "Find the number of ordered pairs $(x,y)$, where both $x$ and $y$ are integers between $-100$ and $100$, inclusive, such that $12x^{2}-xy-6y^{2}=0$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Factor the left-hand side of the equation:\n",
      "\n",
      "$12x^{2} - xy - 6y^{2} = (3x + 2y)(3x - 2y) = 0$\n",
      "\n",
      "Step 2: Now, we can see that either $3x + 2y = 0$ or $3x - 2y = 0$.\n",
      "\n",
      "Step 3: Solve each of these equations separately:\n",
      "\n",
      "$3x + 2y = 0 \\Rightarrow x = -2y/3$\n",
      "\n",
      "$3x - 2y = 0 \\Rightarrow x = 2y/3$\n",
      "\n",
      "Step 4: Now, we have two solutions: $(x,y) = (-2y/3, 2y/3)$ and $(x,y) = (2y/3, -2y/3)$.\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "There are 2 ordered pairs $(x,y)$ that satisfy the equation: $(-2y/3, 2y/3)$ and $(2y/3, -2y/3)$.\n",
      "\n",
      "So, the final answer is:\n",
      "\n",
      "Final Answer: 2.\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "There are $8!=40320$ eight-digit positive integers that use each of the digits $1,2,3,4,5,6,7,8$ exactly once. Let $N$ be the number of these integers that are divisible by 22. Find the difference between $N$ and 2025.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Count the number of integers that are divisible by 22.\n",
      "\n",
      "We can use the fact that each of the digits $1, 2, 3, 4, 5, 6, 7, 8$ appears exactly once in each of the 8! = 40320 eight-digit positive integers. Therefore, the number of integers divisible by 22 is:\n",
      "\n",
      "40320 / 22 = 1825\n",
      "\n",
      "Step 2: Find the difference between $N$ and 2025.\n",
      "\n",
      "We are given that $N$ is the number of integers that are divisible by 22. Since we have just found that 1825 is the number of integers divisible by 22, we can subtract 1825 from 2025 to find the difference:\n",
      "\n",
      "2025 - 1825 = 200\n",
      "\n",
      "Final Answer: 200\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "An isosceles trapezoid has an inscribed circle tangent to each of its four sides. The radius of the circle is 3, and the area of the trapezoid is 72. Let the parallel sides of the trapezoid have lengths $r$ and $s$, with $r \\neq s$. Find $r^{2}+s^{2}$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Draw a circle with radius 3, centered at the midpoint of the line segment joining the midpoints of the two parallel sides of the trapezoid.\n",
      "\n",
      "Step 2: Use the properties of similar triangles to find the length of the altitude to the circle from the midpoint of each of the two parallel sides.\n",
      "\n",
      "Step 3: Use the Pythagorean theorem to find the length of the side of the trapezoid opposite the altitude.\n",
      "\n",
      "Step 4: Use the fact that the area of the trapezoid is equal to the area of the triangle formed by the two parallel sides and the altitude, to find the length of the other side of the trapezoid.\n",
      "\n",
      "Step 5: Use the fact that the radius of the circle is equal to the length of the altitude to find the length of the side of the triangle opposite the radius.\n",
      "\n",
      "Step 6: Use the Pythagorean theorem to find the length of the side of the triangle opposite the radius.\n",
      "\n",
      "Final Answer: $r^2 + s^2 = 72$\n",
      "\n",
      "Note: Throughout this solution, we are using the fact that the altitude to the circle is also the midpoint of the side of the trapezoid opposite the altitude.\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "The twelve letters $A,B,C,D,E,F,G,H,I,J,K$, and $L$ are randomly grouped into six pairs of letters. The two letters in each pair are placed next to each other in alphabetical order to form six two-letter words, and those six words are listed alphabetically. For example, a possible result is $AB,CJ,DG,EK,FL,HI$. The probability that the last word listed contains $G$ is $\\frac{m}{n}$, where $m$ and $n$ are relatively prime positive integers. Find $m+n$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: List all possible pairs of letters that can be formed from the 12 letters $A,B,C,D,E,F,G,H,I,J,K$, and $L$.\n",
      "\n",
      "Possible pairs:\n",
      "\n",
      "$AB, AC, AD, AE, AF, BD, BE, BF, CD, CE, CF, DE, DF, EG, FD, FE, GE, GF$\n",
      "\n",
      "Step 2: For each pair of letters, calculate the probability that the last word listed contains $G$.\n",
      "\n",
      "Probability of $AB$: $\\frac{1}{2}$\n",
      "Probability of $CD$: $\\frac{1}{2}$\n",
      "Probability of $EF$: $\\frac{1}{2}$\n",
      "Probability of $GF$: $\\frac{1}{2}$\n",
      "Probability of $HD$: $\\frac{1}{2}$\n",
      "Probability of $JE$: $\\frac{1}{2}$\n",
      "\n",
      "Step 3: Calculate the sum of the probabilities obtained in Step 2.\n",
      "\n",
      "Sum of probabilities: $\\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} = \\frac{7}{8}$\n",
      "\n",
      "Step 4: Find the value of $m$ and $n$.\n",
      "\n",
      "Since the probability that the last word listed contains $G$ is $\\frac{m}{n}$, where $m$ and $n$ are relatively prime positive integers, we can write:\n",
      "\n",
      "$m = 7$ and $n = 8$\n",
      "\n",
      "Step 5: Calculate the value of $m+n$.\n",
      "\n",
      "$m + n = 7 + 8 = 15$\n",
      "\n",
      "Final Answer: $m+n = 15$\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "Let $k$ be real numbers such that the system $|25+20i-z|=5$ and $|z-4-k|=|z-3i-k|$ has exactly one complex solution $z$. The sum of all possible values of $k$ can be written as $\\frac{m}{n}$, where $m$ and $n$ are relatively prime positive integers. Find $m+n$. Here $i=\\sqrt{-1}$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Solve the first equation for $z$ in terms of $k$:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "|25+20i-z| &= 5 \\\\\n",
      "25+20i-z &= 5(1+i)\n",
      "\\end{aligned}$$\n",
      "\n",
      "Now, we can solve for $z$ in terms of $k$:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "z &= 5(1+i) + 20i - 25 \\\\\n",
      "z &= 5(1+i) + 20i - 25 \\\\\n",
      "z &= 5(1+i) + 20i - 25 \\\\\n",
      "z &= 5(1+i) + 20i - 25\n",
      "\\end{aligned}$$\n",
      "\n",
      "Step 2: Solve the second equation for $k$ in terms of $z$:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "|z-4-k| &= |z-3i-k| \\\\\n",
      "(z-4-k)(z-3i-k) &= (z-3i-k)(z-4-k)\n",
      "\\end{aligned}$$\n",
      "\n",
      "Now, we can solve for $k$ in terms of $z$:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "k &= (z-4-k)(z-3i-k) \\\\\n",
      "k &= (z-3i-k)(z-4-k)\n",
      "\\end{aligned}$$\n",
      "\n",
      "Step 3: Now, we have two equations and two unknowns ($k$ and $z$). Solve for $k$ and $z$ simultaneously:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "k &= (z-3i-k)(z-4-k) \\\\\n",
      "z &= 5(1+i) + 20i - 25\n",
      "\\end{aligned}$$\n",
      "\n",
      "Solving for $k$, we get:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "k &= (z-3i-k)(z-4-k) \\\\\n",
      "k &= (5(1+i) + 20i - 25)(5(1+i) + 20i - 25)\n",
      "\\end{aligned}$$\n",
      "\n",
      "Now, we can simplify the expression for $k$:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "k &= 25(1+i)^2 + 40i - 50\n",
      "\\end{aligned}$$\n",
      "\n",
      "Step 4: Now, we have the value of $k$. To find the value of $m+n$, we can divide the expression for $k$ by the expression for $n$:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "m+n &= \\frac{k}{n} \\\\\n",
      "m+n &= \\frac{25(1+i)^2 + 40i - 50}{n}\n",
      "\\end{aligned}$$\n",
      "\n",
      "Now, we can simplify the expression for $m+n$:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "m+n &= \\frac{25(1+i)^2 + 40i - 50}{n} \\\\\n",
      "m+n &= \\frac{25(1+i)^2 + 40i - 50}{n}\n",
      "\\end{aligned}$$\n",
      "\n",
      "The final answer is:\n",
      "\n",
      "Final Answer: $m+n = 25(1+i)^2 + 40i - 50$.\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "The parabola with equation $y=x^{2}-4$ is rotated $60^{\\circ}$ counterclockwise around the origin. The unique point in the fourth quadrant where the original parabola and its image intersect has $y$-coordinate $\\frac{a-\\sqrt{b}}{c}$, where $a$, $b$, and $c$ are positive integers, and $a$ and $c$ are relatively prime. Find $a+b+c$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Rotate the parabola $y=x^{2}-4$ counterclockwise by $60^{\\circ}$ around the origin.\n",
      "\n",
      "$y = (x + 2)/(x - 2)$\n",
      "\n",
      "Step 2: Find the unique point in the fourth quadrant where the original parabola and its image intersect.\n",
      "\n",
      "$x = 2 + (2 \\times (x + 2)/(x - 2)) = 2 + (2 \\times (x + 2)/(x + 2)) = 2 + (2 \\times x)/(x + 2)$\n",
      "\n",
      "Step 3: Find the $y$-coordinate of the point in the fourth quadrant.\n",
      "\n",
      "$y = (x + 2)/(x + 2) = x/x + 2 = x/x + 1$\n",
      "\n",
      "Step 4: Find the value of $a$, $b$, and $c$.\n",
      "\n",
      "$a = x/x + 2 = x + 2$\n",
      "$b = (x + 2)/(x + 2) = 1$\n",
      "$c = (x + 2)/(x + 2) = 1$\n",
      "\n",
      "Step 5: Find $a+b+c$.\n",
      "\n",
      "$a + b + c = a + 1 + 1 = 2 + 1 = 3$\n",
      "\n",
      "Final Answer: $a+b+c = 3$.\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "The 27 cells of a $3\\times9$ grid are filled in using the numbers 1 through 9 so that each row contains 9 different numbers, and each of the three $3\\times3$ blocks heavily outlined in the example below contains 9 different numbers, as in the first three rows of a Sudoku puzzle. \n",
      " | 4 | 2 | 8 | 9 | 6 | 3 | 1 | 7 | 5 | \n",
      " | 3 | 7 | 9 | 5 | 2 | 1 | 6 | 8 | 4 | \n",
      " | 5 | 6 | 1 | 8 | 4 | 7 | 9 | 2 | 3 | \n",
      " The number of different ways to fill such a grid can be written as $p^a\\cdot q^b\\cdot r^c\\cdot s^d$, where $p,q,r,$ and $s$ are distinct prime numbers and $a,b,c,$ and $d$ are positive integers. Find $p\\cdot a+q\\cdot b+r\\cdot c+s\\cdot d$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Final Answer: 3535353535\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "A piecewise linear periodic function is defined by $f(x)=\\begin{cases}x&\\text{if }x\\in[-1,1)\\\\2-x&\\text{if }x\\in[1,3)\\end{cases}$ and $f(x+4)=f(x)$ for all real numbers $x$. The graph of $f(x)$ has the sawtooth pattern. The parabola $x=34y^2$ intersects the graph of $f(x)$ at finitely many points. The sum of the $y$-coordinates of these intersection points can be expressed in the form $\\frac{a+b\\sqrt{c}}{d}$, where $a,b,c,$ and $d$ are positive integers, $a,b,$ and $d$ have greatest common divisor equal to 1, and $c$ is not divisible by the square of any prime. Find $a+b+c+d$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Final Answer: 125\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "The set of points in 3-dimensional coordinate space that lie in the plane $x+y+z=75$ whose coordinates satisfy the inequalities $x-yz<y-zx<z-xy$ forms three disjoint convex regions. Exactly one of those regions has finite area. The area of this finite region can be expressed in the form $a\\sqrt{b}$, where $a$ and $b$ are positive integers and $b$ is not divisible by the square of any prime. Find $a+b$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Find the equation of the plane $x+y+z=75$.\n",
      "\n",
      "$x + y + z = 75$\n",
      "\n",
      "Step 2: Find the equation of the plane that is perpendicular to the previous plane and passes through the point $(1,1,1)$.\n",
      "\n",
      "$x + y + z = 75$ and $x + y + z = 75$\n",
      "\n",
      "Step 3: Find the equation of the plane that is perpendicular to the previous plane and passes through the point $(1,1,1)$.\n",
      "\n",
      "$x + y + z = 75$ and $x + y + z = 75$\n",
      "\n",
      "Step 4: Find the point of intersection of the three planes.\n",
      "\n",
      "$(1,1,1)$\n",
      "\n",
      "Step 5: Find the volume of the solid formed by the intersection of the three planes.\n",
      "\n",
      "Volume = $1^3 + 1^3 + 1^3 = 3$\n",
      "\n",
      "Step 6: Find the area of the plane that is perpendicular to the previous plane and passes through the point $(1,1,1)$.\n",
      "\n",
      "Area = $1^2 + 1^2 + 1^2 = 3$\n",
      "\n",
      "Step 7: Find the area of the solid formed by the intersection of the three planes.\n",
      "\n",
      "Area = $3$\n",
      "\n",
      "Step 8: Find the ratio of the area of the finite region to the area of the solid.\n",
      "\n",
      "Ratio = $3/3 = 1$\n",
      "\n",
      "Final Answer: $a+b = 1$\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "Alex divides a disk into four quadrants with two perpendicular diameters intersecting at the center of the disk. He draws 25 more line segments through the disk, drawing each segment by selecting two points at random on the perimeter of the disk in different quadrants and connecting those two points. Find the expected number of regions into which these 27 line segments divide the disk.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Draw two perpendicular diameters through the center of the disk, intersecting at the center.\n",
      "\n",
      "Step 2: For each of the 25 line segments drawn in step 1, select two points on the perimeter of the disk in different quadrants.\n",
      "\n",
      "Step 3: Connect the two points on the perimeter of the disk to form a line segment.\n",
      "\n",
      "Step 4: Repeat steps 2 and 3 for all 25 line segments.\n",
      "\n",
      "Expected number of regions into which the 27 line segments divide the disk:\n",
      "\n",
      "Final Answer: 11\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "Let $ABCDE$ be a convex pentagon with $AB=14, BC=7, CD=24, DE=13, EA=26,$ and $\\angle B=\\angle E=60^\\circ$. For each point $X$ in the plane, define $f(X)=AX+BX+CX+DX+EX$. The least possible value of $f(X)$ can be expressed as $m+n\\sqrt{p}$, where $m$ and $n$ are positive integers and $p$ is not divisible by the square of any prime. Find $m+n+p$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Calculate the value of $f(X)$ for each point $X$ in the plane.\n",
      "\n",
      "$f(X) = AX + BX + CX + DX + EX = (14 + 7 + 24 + 13 + 26)X + (14 + 7 + 24 + 13 + 26)X = 14X + 67X$\n",
      "\n",
      "Step 2: Find the least possible value of $f(X)$ by finding the smallest positive integer $n$ such that $n\\sqrt{p} \\leq f(X)$ for all $X$.\n",
      "\n",
      "$n = \\lceil \\sqrt{p} \\rceil$\n",
      "\n",
      "Step 3: Express $f(X)$ as $m + n\\sqrt{p}$, where $m$ and $n$ are positive integers and $p$ is not divisible by the square of any prime.\n",
      "\n",
      "$f(X) = m + n\\sqrt{p}$\n",
      "\n",
      "Step 4: Find the values of $m$ and $n$.\n",
      "\n",
      "$m = \\lfloor f(X) \\rfloor = \\lfloor 14 + 67X \\rfloor$\n",
      "\n",
      "$n = \\frac{f(X)}{67X} = \\frac{14 + 67X}{67X}$\n",
      "\n",
      "Step 5: Calculate the final answer.\n",
      "\n",
      "Final Answer: $m + n = 14 + 67X + \\frac{14 + 67X}{67X} = 14 + 67X + \\frac{14}{67X}$\n",
      "\n",
      "Note: The final answer is a fraction, so we need to find the least common multiple of the denominator and the numerator to simplify it. In this case, the least common multiple of 67 and 14 is 1088, so we can simplify the fraction to:\n",
      "\n",
      "Final Answer: $m + n = 14 + 67X + \\frac{14}{1088}$\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "Let $N$ denote the number of ordered triples of positive integers $(a,b,c)$ such that $a,b,c\\leq3^6$ and $a^3+b^3+c^3$ is a multiple of $3^7$. Find the remainder when $N$ is divided by $1000$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's the solution to the problem:\n",
      "\n",
      "Step 1: Find the number of triples $(a,b,c)$ such that $a^3+b^3+c^3$ is a multiple of $3^7$.\n",
      "\n",
      "Let $a = 3k$, $b = 3l$, and $c = 3m$ for integers $k$, $l$, and $m$. Then,\n",
      "\n",
      "$$a^3 + b^3 + c^3 = (3k)^3 + (3l)^3 + (3m)^3 = 3^3(k^3 + l^3 + m^3)$$\n",
      "\n",
      "Since $k^3 + l^3 + m^3$ is a cube, it is a multiple of $3^3$. Therefore, $a^3 + b^3 + c^3$ is a multiple of $3^7$.\n",
      "\n",
      "Now, we count the number of such triples. There are $3^3$ choices for $k$, $3^3$ choices for $l$, and $3^3$ choices for $m$, for a total of $3^9$ triples.\n",
      "\n",
      "Step 2: Find the number of triples $(a,b,c)$ such that $a^3+b^3+c^3$ is a multiple of $3^7$ and $a,b,c\\leq3^6$.\n",
      "\n",
      "From Step 1, we know that there are $3^9$ triples such that $a^3+b^3+c^3$ is a multiple of $3^7$. Now, we count the number of triples that satisfy the additional condition $a,b,c\\leq3^6$.\n",
      "\n",
      "Let $a = 3k$, $b = 3l$, and $c = 3m$ for integers $k$, $l$, and $m$. Then,\n",
      "\n",
      "$$a^3 + b^3 + c^3 = (3k)^3 + (3l)^3 + (3m)^3 \\leq (3^6)^3 = 27^3$$\n",
      "\n",
      "Therefore, there are $3^6$ choices for $k$, $3^6$ choices for $l$, and $3^6$ choices for $m$, for a total of $3^6\\times3^6\\times3^6 = 3^{18}$ triples that satisfy both conditions.\n",
      "\n",
      "Step 3: Find the final answer by dividing the total number of triples by 1000.\n",
      "\n",
      "There are $3^9\\times3^6 = 3^{155}$ triples in total. To find the remainder when $3^{155}$ is divided by 1000, we can perform the division:\n",
      "\n",
      "$$3^{155} \\div 1000 = 3 \\times 1000 + 55$$\n",
      "\n",
      "Therefore, the final answer is:\n",
      "\n",
      "Final Answer: $55$.\n",
      "   acc=0.000  (0/15)  time=139.3s\n",
      "[DW] alpha=0, k=32 → generating ...\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "Find the sum of all integer bases $b>9$ for which $17_{b}$ is a divisor of $97_{b}$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Great, let's dive into the problem!\n",
      "\n",
      "Step 1: List all possible integer bases $b>9$\n",
      "\n",
      "We need to find all integer bases $b>9$ such that $17_b$ is a divisor of $97_b$.\n",
      "\n",
      "Let's list all possible bases $b>9$:\n",
      "\n",
      "$b = 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20$\n",
      "\n",
      "Step 2: Check if $17_b$ is a divisor of $97_b$\n",
      "\n",
      "For each base $b$ in the list, we need to check if $17_b$ is a divisor of $97_b$.\n",
      "\n",
      "Let's check for each base:\n",
      "\n",
      "$b = 10$: $17_b = 17 \\times 1 = 17$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 11$: $17_b = 17 \\times 2 = 34$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 12$: $17_b = 17 \\times 3 = 51$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 13$: $17_b = 17 \\times 4 = 68$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 14$: $17_b = 17 \\times 5 = 85$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 15$: $17_b = 17 \\times 6 = 102$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 16$: $17_b = 17 \\times 7 = 119$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 17$: $17_b = 17 \\times 8 = 146$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 18$: $17_b = 17 \\times 9 = 153$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 19$: $17_b = 17 \\times 10 = 164$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "$b = 20$: $17_b = 17 \\times 11 = 177$ is not a divisor of $97_b = 97$.\n",
      "\n",
      "Therefore, the only base $b$ for which $17_b$ is a divisor of $97_b$ is $b = 19$.\n",
      "\n",
      "Step 3: Find the sum of all integer bases $b>9$ for which $17_b$ is a divisor of $97_b$\n",
      "\n",
      "Since we found only one base $b = 19$ for which $17_b$ is a divisor of $97_b$, the sum of all integer bases $b>9$ for which $17_b$ is a divisor of $97_b$ is:\n",
      "\n",
      "Final Answer: $1 + 1 = 2$\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "On $\\triangle ABC$ points $A,D,E$, and $B$ lie that order on side $\\overline{AB}$ with $AD=4, DE=16$, and $EB=8$. Points $A,F,G$, and $C$ lie in that order on side $\\overline{AC}$ with $AF=13, FG=52$, and $GC=26$. Let $M$ be the reflection of $D$ through $F$, and let $N$ be the reflection of $G$ through $E$. Quadrilateral $DEGF$ has area 288. Find the area of heptagon $AFNBCEM$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure, I'd be happy to help you solve this problem! Here are the steps I used to find the area of the heptagon $AFNBCEM$:\n",
      "\n",
      "Step 1: Find the distance between points $A$ and $M$, where $M$ is the reflection of $D$ through $F$.\n",
      "\n",
      "Using the given information, we know that $AD = 4$ and $FM = 13$, so we can find the distance between $A$ and $M$ as follows:\n",
      "\n",
      "$AM = AD + FM = 4 + 13 = 17$\n",
      "\n",
      "Step 2: Find the distance between points $B$ and $N$, where $N$ is the reflection of $G$ through $E$.\n",
      "\n",
      "Using the given information, we know that $DE = 16$ and $EN = 52$, so we can find the distance between $B$ and $N$ as follows:\n",
      "\n",
      "$BN = DE + EN = 16 + 52 = 68$\n",
      "\n",
      "Step 3: Find the area of the quadrilateral $DEGF$.\n",
      "\n",
      "Using the given information, we know that $DE = 16$ and $FG = 52$, so we can find the area of $DEGF$ as follows:\n",
      "\n",
      "Area of $DEGF = \\frac{1}{2} \\times (16 \\times 52) = 288$\n",
      "\n",
      "Step 4: Find the area of the heptagon $AFNBCEM$.\n",
      "\n",
      "Using the fact that the area of a heptagon is equal to the sum of the areas of its non-overlapping triangles, we can find the area of $AFNBCEM$ as follows:\n",
      "\n",
      "Area of $AFNBCEM = \\frac{1}{2} \\times (AF + BF + CF + DF + EB + FE + CE) = \\frac{1}{2} \\times (17 + 13 + 8 + 4 + 8 + 52 + 26) = 176$\n",
      "\n",
      "Therefore, the final answer is:\n",
      "\n",
      "Final Answer: $176$\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "The 9 members of a baseball team went to an ice cream parlor after their game. Each player had a singlescoop cone of chocolate, vanilla, or strawberry ice cream. At least one player chose each flavor, and the number of players who chose chocolate was greater than the number of players who chose vanilla, which was greater than the number of players who chose strawberry. Let $N$ be the number of different assignments of flavors to players that meet these conditions. Find the remainder when $N$ is divided by 1000.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Sure! Here's how I would solve the problem:\n",
      "\n",
      "Let's say the number of players is $P$.\n",
      "\n",
      "1. The number of players who chose chocolate is greater than the number of players who chose vanilla, so the number of players who chose chocolate is $C \\geq V$.\n",
      "2. The number of players who chose vanilla is greater than the number of players who chose strawberry, so the number of players who chose vanilla is $V \\geq S$.\n",
      "3. The number of different assignments of flavors to players is $N = C + V + S$.\n",
      "4. Since at least one player chose each flavor, we have $C + V + S \\geq P$.\n",
      "5. Solving for $N$ in equation (4) gives $N = (C + V + S) - P \\geq 0$.\n",
      "6. Since $N$ is divided by 1000, we have $N \\mod 1000 = 0$.\n",
      "\n",
      "Therefore, the final answer is:\n",
      "\n",
      "Final Answer: $N = 999$.\n",
      "Out [INST] <<SYS>>\n",
      "You are a careful competition mathematician. Solve the problem step by step, then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\n",
      "<</SYS>>\n",
      "\n",
      "Find the number of ordered pairs $(x,y)$, where both $x$ and $y$ are integers between $-100$ and $100$, inclusive, such that $12x^{2}-xy-6y^{2}=0$.\n",
      "\n",
      "Do not include units unless necessary. Do not include extra text after the final answer line. [/INST]  Great, let's solve the problem step by step:\n",
      "\n",
      "Step 1: Factor the left-hand side of the equation:\n",
      "\n",
      "$12x^{2} - xy - 6y^{2} = (2x + 3y)(2x - 3y) = 0$\n",
      "\n",
      "Step 2: Now, we can see that $2x + 3y = 0$ or $2x - 3y = 0$.\n",
      "\n",
      "Step 3: Solve for $x$ in the first equation:\n",
      "\n",
      "$2x + 3y = 0 \\Rightarrow 2x = -3y$\n",
      "\n",
      "Step 4: Solve for $x$ in the second equation:\n",
      "\n",
      "$2x - 3y = 0 \\Rightarrow x = \\frac{3y}{2}$\n",
      "\n",
      "Step 5: Now, we have two solutions for $x$: $x = -\\frac{3y}{2}$ and $x = \\frac{3y}{2}$.\n",
      "\n",
      "Step 6: To find the number of pairs $(x,y)$, we need to count the number of pairs that satisfy the condition.\n",
      "\n",
      "For the first solution, $x = -\\frac{3y}{2}$, we have:\n",
      "\n",
      "$-\\frac{3y}{2} \\in [-100, 100]$ implies $y \\in [-300, 300]$.\n",
      "\n",
      "So, the number of pairs $(x,y)$ that satisfy the condition is:\n",
      "\n",
      "$300$\n",
      "\n",
      "For the second solution, $x = \\frac{3y}{2}$, we have:\n",
      "\n",
      "$\\frac{3y}{2} \\in [-100, 100]$ implies $y \\in [-150, 150]$.\n",
      "\n",
      "So, the number of pairs $(x,y)$ that satisfy the condition is:\n",
      "\n",
      "$150$\n",
      "\n",
      "Therefore, the final answer is:\n",
      "\n",
      "Final Answer: $450$ pairs.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 374\u001b[39m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m big\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# ---------- Example call ----------\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# big_df = run_all_models_on_aime(MODELS)  # uses your MODELS list defined earlier\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Or just one:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m df_single = \u001b[43mrun_aime_dw_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_aime_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAIME_PATHS_TRY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 291\u001b[39m, in \u001b[36mrun_aime_dw_compare\u001b[39m\u001b[34m(model_path, aime_records, ks, alphas)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[DW] alpha=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m → generating ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    290\u001b[39m t0 = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m steered_text = \u001b[43manswer_batch_steered_dw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcombined_coefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoefs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_NEW_TOKENS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m eval_res = evaluate_run(gold, steered_text)\n\u001b[32m    298\u001b[39m dt = time.time() - t0\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 211\u001b[39m, in \u001b[36manswer_batch_steered_dw\u001b[39m\u001b[34m(model, tokenizer, questions, combined_coefs, alpha, max_new_tokens)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[32m    210\u001b[39m     prompt = build_math_chat_prompt(tokenizer, q)\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     out = \u001b[43mgenerate_with_head_intervention_gpu\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcombined_coefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcombined_coefs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_features\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdevice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOut\u001b[39m\u001b[33m\"\u001b[39m, out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    222\u001b[39m     results.append(out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 197\u001b[39m, in \u001b[36mgenerate_with_head_intervention_gpu\u001b[39m\u001b[34m(model, tokenizer, prompts, alpha, max_new_tokens, combined_coefs, return_features, device)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# generate\u001b[39;00m\n\u001b[32m    196\u001b[39m inp = tokenizer(prompt, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).input_ids.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m tokens = out[\u001b[32m0\u001b[39m].cpu().numpy()\n\u001b[32m    200\u001b[39m answer = tokenizer.decode(out[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dotty-project/transformers/src/transformers/generation/utils.py:2623\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2615\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2616\u001b[39m         input_ids=input_ids,\n\u001b[32m   2617\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2618\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2619\u001b[39m         **model_kwargs,\n\u001b[32m   2620\u001b[39m     )\n\u001b[32m   2622\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2623\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2624\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2634\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2635\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2636\u001b[39m         input_ids=input_ids,\n\u001b[32m   2637\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2638\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2639\u001b[39m         **model_kwargs,\n\u001b[32m   2640\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dotty-project/transformers/src/transformers/generation/utils.py:3607\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3605\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3606\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3607\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3609\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3610\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3611\u001b[39m     outputs,\n\u001b[32m   3612\u001b[39m     model_kwargs,\n\u001b[32m   3613\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3614\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dotty-project/transformers/src/transformers/utils/generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dotty-project/transformers/src/transformers/models/llama/modeling_llama.py:558\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    553\u001b[39m output_hidden_states = (\n\u001b[32m    554\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    555\u001b[39m )\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    571\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dotty-project/transformers/src/transformers/utils/generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dotty-project/transformers/src/transformers/models/llama/modeling_llama.py:446\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    444\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    458\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dotty-project/transformers/src/transformers/modeling_layers.py:48\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dotty-project/transformers/src/transformers/models/llama/modeling_llama.py:297\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    294\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dotty-project/transformers/src/transformers/models/llama/modeling_llama.py:264\u001b[39m, in \u001b[36mLlamaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    251\u001b[39m     attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m    253\u001b[39m attn_output, attn_weights = attention_interface(\n\u001b[32m    254\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    255\u001b[39m     query_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    261\u001b[39m     **kwargs,\n\u001b[32m    262\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m attn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhead_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    266\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/torch/nn/modules/module.py:1818\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1816\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[32m   1817\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1818\u001b[39m     hook_result = \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1820\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1821\u001b[39m     result = hook_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/baukit/nethook.py:73\u001b[39m, in \u001b[36mTrace.__init__.<locals>.retain_hook\u001b[39m\u001b[34m(m, inputs, output)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretain_hook\u001b[39m(m, inputs, output):\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m edit_output:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m         output = \u001b[43minvoke_with_optional_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43medit_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m retain_input:\n\u001b[32m     77\u001b[39m         retainer.input = recursive_copy(\n\u001b[32m     78\u001b[39m             inputs[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m inputs,\n\u001b[32m     79\u001b[39m             clone=clone,\n\u001b[32m     80\u001b[39m             detach=detach,\n\u001b[32m     81\u001b[39m             retain_grad=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     82\u001b[39m         )  \u001b[38;5;66;03m# retain_grad applies to output only.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/linear-probe/lib/python3.12/site-packages/baukit/nethook.py:427\u001b[39m, in \u001b[36minvoke_with_optional_args\u001b[39m\u001b[34m(fn, *args, **kwargs)\u001b[39m\n\u001b[32m    425\u001b[39m argspec = inspect.getfullargspec(fn)\n\u001b[32m    426\u001b[39m pass_args = []\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m used_kw = \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m unmatched_pos = []\n\u001b[32m    429\u001b[39m used_pos = \u001b[32m0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# AIME 2025 evaluation with DW-vote steering\n",
    "# ===============================================\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# ---------- Config ----------\n",
    "AIME_PATHS_TRY = [\n",
    "    \"data/aime2025-I.jsonl\",  # preferred: one JSON per line with {\"question\": \"...\", \"answer\": 123}\n",
    "]\n",
    "DW_PREFIX = \"politician\"          # ridge prefix trained on DW-vote prompts\n",
    "ALPHAS = [-20, 0, 20]\n",
    "K_LIST = [32]                  # number of heads to combine; can sweep more if you like\n",
    "MAX_NEW_TOKENS = 2048\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.95\n",
    "SEED = 42\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def _set_seed(seed: int = SEED):\n",
    "    import torch, numpy as np, random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "_set_seed(SEED)\n",
    "\n",
    "def load_aime_dataset(paths: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load AIME 2025 dataset from jsonl or csv.\n",
    "    Expected schema:\n",
    "      - jsonl: one object per line with keys {\"question\": str, \"answer\": int or str}\n",
    "      - csv  : columns [\"question\",\"answer\"]\n",
    "    Returns list of dicts: [{\"qid\": int, \"question\": str, \"answer\": str}]\n",
    "    \"\"\"\n",
    "    for p in paths:\n",
    "        if os.path.isfile(p):\n",
    "            ext = os.path.splitext(p)[1].lower()\n",
    "            records = []\n",
    "            if ext == \".jsonl\":\n",
    "                with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "                    for i, line in enumerate(f):\n",
    "                        obj = json.loads(line)\n",
    "                        q = str(obj[\"question\"]).strip()\n",
    "                        a = str(obj[\"answer\"]).strip()\n",
    "                        records.append({\"qid\": i, \"question\": q, \"answer\": a})\n",
    "            elif ext == \".csv\":\n",
    "                df = pd.read_csv(p)\n",
    "                assert {\"question\",\"answer\"}.issubset(df.columns)\n",
    "                for i, row in df.iterrows():\n",
    "                    records.append({\"qid\": i, \"question\": str(row[\"question\"]).strip(), \"answer\": str(row[\"answer\"]).strip()})\n",
    "            print(f\"Loaded AIME 2025 from {p}  (N={len(records)})\")\n",
    "            return records\n",
    "\n",
    "    # Fallback tiny mock set so code runs even without the real file\n",
    "    print(\"AIME 2025 file not found. Using a tiny mock dataset (2 items) for a dry run.\")\n",
    "    mock = [\n",
    "        {\n",
    "            \"qid\": 0,\n",
    "            \"question\": \"If (x+1)^2 = 25 and x is positive, compute x.\",\n",
    "            \"answer\": \"4\"\n",
    "        },\n",
    "        {\n",
    "            \"qid\": 1,\n",
    "            \"question\": \"Let S be the sum of the first 10 positive integers. What is S?\",\n",
    "            \"answer\": \"55\"\n",
    "        },\n",
    "    ]\n",
    "    return mock\n",
    "\n",
    "def build_math_chat_prompt(tokenizer, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a chat-formatted prompt asking for a single final numeric answer.\n",
    "    You can adjust the instruction style to match your model family.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a careful competition mathematician. Solve the problem step by step, \"\n",
    "                \"then give ONLY the final numeric answer on the last line in the form: Final Answer: <number>.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"{question}\\n\\n\"\n",
    "                \"Do not include units unless necessary. Do not include extra text after the final answer line.\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "    # Use tokenizer chat template if available; otherwise fall back to a plain prompt\n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        try:\n",
    "            return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # fallback\n",
    "    sys = messages[0][\"content\"]\n",
    "    usr = messages[1][\"content\"]\n",
    "    return f\"<|system|>\\n{sys}\\n<|user|>\\n{usr}\\n<|assistant|>\\n\"\n",
    "\n",
    "_FINAL_ANSWER_PATTERNS = [\n",
    "    r\"Final Answer:\\s*([-+]?\\d+)\",            # Final Answer: 123\n",
    "    r\"\\\\boxed\\{([^}]+)\\}\",                     # \\boxed{123}\n",
    "    r\"Answer:\\s*([-+]?\\d+)\",                   # Answer: 123\n",
    "    r\"=+\\s*([-+]?\\d+)\\s*$\",                    # ends with = 123\n",
    "]\n",
    "\n",
    "def extract_numeric_answer(text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Try to extract the final numeric answer (integer) from model text.\n",
    "    Returns string of integer if found, else None.\n",
    "    \"\"\"\n",
    "    # prioritize explicit \"Final Answer\"\n",
    "    for pat in _FINAL_ANSWER_PATTERNS:\n",
    "        m = re.search(pat, text, flags=re.IGNORECASE | re.MULTILINE)\n",
    "        if m:\n",
    "            cand = m.group(1).strip()\n",
    "            # strip common wrappers\n",
    "            cand = re.sub(r\"[^\\d\\-+]\", \"\", cand)\n",
    "            # ensure it's integer-like\n",
    "            if re.fullmatch(r\"[-+]?\\d+\", cand):\n",
    "                return str(int(cand))\n",
    "    # fallback: last integer in the text\n",
    "    ints = re.findall(r\"[-+]?\\d+\", text)\n",
    "    if ints:\n",
    "        return str(int(ints[-1]))\n",
    "    return None\n",
    "\n",
    "def grade_pred(gold: str, pred: Optional[str]) -> bool:\n",
    "    \"\"\"\n",
    "    AIME answers are integers (or short numbers). Here we treat exact integer match as correct.\n",
    "    You can expand with tolerance if your dataset includes non-integers.\n",
    "    \"\"\"\n",
    "    if pred is None:\n",
    "        return False\n",
    "    # normalize\n",
    "    try:\n",
    "        g = int(str(gold).strip())\n",
    "        p = int(str(pred).strip())\n",
    "        return g == p\n",
    "    except Exception:\n",
    "        # if not integer, do string compare after minimal cleanup\n",
    "        return str(gold).strip() == str(pred).strip()\n",
    "\n",
    "def answer_batch_unsteered(model, tokenizer, questions: List[str], max_new_tokens=256) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate answers with no interventions.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    outs = []\n",
    "    eos_ids = [tokenizer.eos_token_id]\n",
    "    # add eot if known\n",
    "    try:\n",
    "        eot_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "        if isinstance(eot_id, int) and eot_id > 0:\n",
    "            eos_ids.append(eot_id)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for q in questions:\n",
    "            prompt = build_math_chat_prompt(tokenizer, q)\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            gen = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=TEMPERATURE,\n",
    "                top_p=TOP_P,\n",
    "                eos_token_id=eos_ids,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "            text = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
    "            # trim prompt if chat template returned in full text\n",
    "            if text.startswith(prompt):\n",
    "                text = text[len(prompt):]\n",
    "            \n",
    "            print(\"Out:\", text)\n",
    "            outs.append(text.strip())\n",
    "    return outs\n",
    "\n",
    "def answer_batch_steered_dw(\n",
    "    model, tokenizer, questions: List[str],\n",
    "    combined_coefs,\n",
    "    alpha: float,\n",
    "    max_new_tokens=256\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate answers with DW-vote steering applied (head intervention).\n",
    "    Uses your previously defined `generate_with_head_intervention_gpu`.\n",
    "    \"\"\"\n",
    "    # We generate one question at a time to reuse your hook logic\n",
    "    results = []\n",
    "    for q in questions:\n",
    "        prompt = build_math_chat_prompt(tokenizer, q)\n",
    "        out = generate_with_head_intervention_gpu(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            prompts=[prompt],\n",
    "            alpha=alpha,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            combined_coefs=combined_coefs,\n",
    "            return_features=False,\n",
    "            device=model.device if hasattr(model, \"device\") else None,\n",
    "        )\n",
    "        print(\"Out\", out[0][\"answer\"])\n",
    "        results.append(out[0][\"answer\"])\n",
    "        \n",
    "    return results\n",
    "\n",
    "def evaluate_run(gold_answers: List[str], raw_outputs: List[str]) -> Dict:\n",
    "    preds = [extract_numeric_answer(t) for t in raw_outputs]\n",
    "    correct = [grade_pred(g, p) for g, p in zip(gold_answers, preds)]\n",
    "    return {\n",
    "        \"n\": len(gold_answers),\n",
    "        \"correct\": int(sum(correct)),\n",
    "        \"acc\": float(np.mean(correct)) if len(correct) else 0.0,\n",
    "        \"preds\": preds,\n",
    "        \"raw\": raw_outputs,\n",
    "        \"is_correct\": correct,\n",
    "    }\n",
    "\n",
    "def run_aime_dw_compare(model_path: str, aime_records: List[Dict], ks=K_LIST, alphas=ALPHAS) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs baseline (unsteered) and DW-steered generations on AIME 2025,\n",
    "    evaluates accuracy, and returns a results DataFrame.\n",
    "    Also writes CSV + a PNG plot to ./results/<model_base>/ .\n",
    "    \"\"\"\n",
    "    import torch\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    questions = [r[\"question\"] for r in aime_records]\n",
    "    gold      = [r[\"answer\"]   for r in aime_records]\n",
    "\n",
    "    # Load model/tokenizer\n",
    "    tokenizer, model = load_tokenizer_and_model(model_path, device=device)\n",
    "    base_name = model_base_name(model_path)\n",
    "\n",
    "\n",
    "    # Ensure output dir\n",
    "    out_dir = os.path.join(\"results\", base_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # ---------- Baseline ----------\n",
    "    print(\"\\n[Baseline] Generating without steering...\")\n",
    "    t0 = time.time()\n",
    "    baseline_text = answer_batch_unsteered(model, tokenizer, questions[:1], max_new_tokens=MAX_NEW_TOKENS)\n",
    "    base_eval = evaluate_run(gold, baseline_text)\n",
    "    print(f\"Baseline AIME acc = {base_eval['acc']:.3f}  ({base_eval['correct']}/{base_eval['n']})  time={time.time()-t0:.1f}s\")\n",
    "\n",
    "    # ---------- Load DW-vote ridge/perf and feats std (through compute_combined_coefs) ----------\n",
    "    print(\"\\n[DW-steering] Loading ridge models & performance...\")\n",
    "    feats = load_feats(model_path=model_path, prefix=DW_PREFIX, results_dir=\"./results\", device=device)\n",
    "    ridge_models, performance = load_ridge_models(model_path, DW_PREFIX)\n",
    "\n",
    "    # For compute_combined_coefs we need feats OR (k, performance); we’ll use k+performance path here.\n",
    "    # If you preloaded feats earlier, you can switch to the feats-based call for speed.\n",
    "\n",
    "    # ---------- Sweep steering settings ----------\n",
    "    rows = []\n",
    "    for k in ks:\n",
    "        # Build steering coefficients [L,H,D] once per k\n",
    "        print(f\"\\nBuilding combined_coefs for k={k} ...\")\n",
    "        coefs = compute_combined_coefs(\n",
    "            feats=feats,                # not using preloaded feats\n",
    "            ridge_models=ridge_models,\n",
    "            k=k,\n",
    "            performance=performance,\n",
    "            device=model.device if hasattr(model, \"device\") else None,\n",
    "        )\n",
    "\n",
    "        for alpha in alphas:\n",
    "            print(f\"[DW] alpha={alpha}, k={k} → generating ...\")\n",
    "            t0 = time.time()\n",
    "            steered_text = answer_batch_steered_dw(\n",
    "                model, tokenizer, questions,\n",
    "                combined_coefs=coefs,\n",
    "                alpha=alpha,\n",
    "                max_new_tokens=MAX_NEW_TOKENS,\n",
    "            )\n",
    "            eval_res = evaluate_run(gold, steered_text)\n",
    "            dt = time.time() - t0\n",
    "            print(f\"   acc={eval_res['acc']:.3f}  ({eval_res['correct']}/{eval_res['n']})  time={dt:.1f}s\")\n",
    "            rows.append({\n",
    "                \"model\": base_name,\n",
    "                \"mode\": \"steered_dw\",\n",
    "                \"alpha\": alpha,\n",
    "                \"k\": k,\n",
    "                \"acc\": eval_res[\"acc\"],\n",
    "                \"correct\": eval_res[\"correct\"],\n",
    "                \"n\": eval_res[\"n\"],\n",
    "            })\n",
    "\n",
    "    # Append baseline row\n",
    "    rows.append({\n",
    "        \"model\": base_name,\n",
    "        \"mode\": \"baseline\",\n",
    "        \"alpha\": 0,\n",
    "        \"k\": 0,\n",
    "        \"acc\": base_eval[\"acc\"],\n",
    "        \"correct\": base_eval[\"correct\"],\n",
    "        \"n\": base_eval[\"n\"],\n",
    "    })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    csv_path = os.path.join(out_dir, \"aime2025_dw_vote_eval.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nSaved summary CSV → {csv_path}\")\n",
    "\n",
    "    # ---------- Plot ----------\n",
    "    # Single-plot requirement (no seaborn, no explicit colors)\n",
    "    fig = plt.figure(figsize=(7, 4.5))\n",
    "    # Plot baseline as a horizontal line\n",
    "    y = base_eval[\"acc\"]\n",
    "    plt.axhline(y=y, linestyle=\"--\", label=f\"Baseline acc = {y:.3f}\")\n",
    "    # Plot steered curves per k\n",
    "    for k in sorted(set(df[df[\"mode\"]==\"steered_dw\"][\"k\"])):\n",
    "        sub = df[(df[\"mode\"]==\"steered_dw\") & (df[\"k\"]==k)].sort_values(\"alpha\")\n",
    "        plt.plot(sub[\"alpha\"].tolist(), sub[\"acc\"].tolist(), marker=\"o\", label=f\"Steered (k={k})\")\n",
    "    plt.xlabel(\"alpha (DW-vote steering strength)\")\n",
    "    plt.ylabel(\"AIME 2025 accuracy\")\n",
    "    plt.title(f\"AIME 2025: Baseline vs DW-steered • {base_name}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    png_path = os.path.join(out_dir, \"aime2025_dw_vote_eval.png\")\n",
    "    plt.savefig(png_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Saved plot PNG → {png_path}\")\n",
    "\n",
    "    # Cleanup VRAM\n",
    "    del model\n",
    "    clean_up(device=None)\n",
    "    return df\n",
    "\n",
    "# ---------- Entry point helper ----------\n",
    "def run_all_models_on_aime(models: List[str] = None):\n",
    "    \"\"\"\n",
    "    Convenience runner: iterate over your MODELS list and compare each.\n",
    "    \"\"\"\n",
    "    records = load_aime_dataset(AIME_PATHS_TRY)\n",
    "    used_models = models if models is not None else MODELS\n",
    "    all_dfs = []\n",
    "    for m in used_models:\n",
    "        print(f\"\\n===== Evaluating {m} on AIME 2025 =====\")\n",
    "        df = run_aime_dw_compare(model_path=m, aime_records=records, ks=K_LIST, alphas=ALPHAS)\n",
    "        all_dfs.append(df.assign(model_path=m))\n",
    "    big = pd.concat(all_dfs, ignore_index=True)\n",
    "    # Also write a combined CSV\n",
    "    out = \"./results/aime2025_dw_vote_eval_all_models.csv\"\n",
    "    os.makedirs(\"./results\", exist_ok=True)\n",
    "    big.to_csv(out, index=False)\n",
    "    print(f\"\\nWrote combined results: {out}\")\n",
    "    return big\n",
    "\n",
    "# ---------- Example call ----------\n",
    "# big_df = run_all_models_on_aime(MODELS)  # uses your MODELS list defined earlier\n",
    "# Or just one:\n",
    "df_single = run_aime_dw_compare(MODELS[0], load_aime_dataset(AIME_PATHS_TRY), ks=[32], alphas=[-20, 0, 20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b42b1",
   "metadata": {},
   "source": [
    "## MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27fb4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grading.grader import grade_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MATH from data/math500.jsonl (N=500)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beafe7b2cd5b4fba81ddee168a265856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DW-steering] Loading ridge models & performance...\n",
      "\n",
      "Building combined_coefs for k=32 ...\n",
      "[DW] alpha=-20, k=32 → generating ...\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# MATH evaluation with DW-vote steering\n",
    "# ===============================================\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "# ---------- Config ----------\n",
    "MATH_PATHS_TRY = [\n",
    "    \"data/math500.jsonl\",     # JSONL with {\"problem\": \"...\", \"solution\": \"...\", \"answer\": \"...\"}\n",
    "]\n",
    "DW_PREFIX = \"politician\"        # or \"dw_vote\" if you want those heads\n",
    "ALPHAS = [-20, 0, 20]\n",
    "K_LIST = [32]\n",
    "MAX_NEW_TOKENS = 1024\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.95\n",
    "SEED = 42\n",
    "LIMIT = 100\n",
    "\n",
    "# ---------- Seed ----------\n",
    "def _set_seed(seed: int = SEED):\n",
    "    import torch, numpy as np, random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "_set_seed(SEED)\n",
    "\n",
    "def extract_predicted_answer(text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extract model final answer:\n",
    "    - Prefer \\boxed{...} if present\n",
    "    - Else look for 'Final Answer:' pattern\n",
    "    - Else fallback to last inline mathy token snippet\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return None\n",
    "\n",
    "    # Common explicit pattern\n",
    "    m = re.search(r\"Final Answer:\\s*(.+?)\\s*$\", text, flags=re.IGNORECASE | re.DOTALL)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "\n",
    "    return None\n",
    "\n",
    "def _load_math_from_jsonl(path: str) -> List[Dict]:\n",
    "    recs = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            obj = json.loads(line)\n",
    "            # Accept several common field names\n",
    "            q = obj.get(\"problem\") or obj.get(\"question\") or obj.get(\"prompt\") or \"\"\n",
    "            a = obj.get(\"answer\") or obj.get(\"final_answer\") or obj.get(\"target\") or \"\"\n",
    "            recs.append({\"qid\": i, \"question\": str(q).strip(), \"answer\": str(a).strip()})\n",
    "    return recs\n",
    "\n",
    "def _load_math_from_csv(path: str) -> List[Dict]:\n",
    "    df = pd.read_csv(path)\n",
    "    # tolerate different header spellings\n",
    "    qcol = \"problem\" if \"problem\" in df.columns else (\"question\" if \"question\" in df.columns else \"prompt\")\n",
    "    acol = \"answer\"  if \"answer\"  in df.columns else (\"final_answer\" if \"final_answer\" in df.columns else None)\n",
    "    if acol is None:\n",
    "        raise ValueError(\"CSV must include an 'answer' (or 'final_answer') column.\")\n",
    "    recs = []\n",
    "    for i, row in df.iterrows():\n",
    "        recs.append({\"qid\": i, \"question\": str(row[qcol]).strip(), \"answer\": str(row[acol]).strip()})\n",
    "    return recs\n",
    "\n",
    "def _load_math_from_dir(path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Hendrycks MATH layout often has many JSON files with fields {\"problem\", \"solution\", \"answer\"}.\n",
    "    \"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(path, \"**\", \"*.json\"), recursive=True))\n",
    "    recs = []\n",
    "    for i, p in enumerate(files):\n",
    "        try:\n",
    "            with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "                obj = json.load(f)\n",
    "            q = obj.get(\"problem\") or obj.get(\"question\") or \"\"\n",
    "            a = obj.get(\"answer\") or obj.get(\"final_answer\") or \"\"\n",
    "            recs.append({\"qid\": i, \"question\": str(q).strip(), \"answer\": str(a).strip()})\n",
    "        except Exception:\n",
    "            continue\n",
    "    return recs\n",
    "\n",
    "def load_math_dataset(paths: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Try JSONL, then CSV, then directory-of-JSON files. If nothing is found,\n",
    "    fall back to a tiny mock set (so the pipeline still runs).\n",
    "    \"\"\"\n",
    "    for p in paths:\n",
    "        if not os.path.exists(p):\n",
    "            continue\n",
    "        if os.path.isdir(p):\n",
    "            recs = _load_math_from_dir(p)\n",
    "            if recs:\n",
    "                print(f\"Loaded MATH from dir {p} (N={len(recs)})\")\n",
    "                return recs\n",
    "        else:\n",
    "            ext = os.path.splitext(p)[1].lower()\n",
    "            if ext == \".jsonl\":\n",
    "                recs = _load_math_from_jsonl(p)\n",
    "                print(f\"Loaded MATH from {p} (N={len(recs)})\")\n",
    "                return recs\n",
    "            elif ext == \".csv\":\n",
    "                recs = _load_math_from_csv(p)\n",
    "                print(f\"Loaded MATH from {p} (N={len(recs)})\")\n",
    "                return recs\n",
    "\n",
    "    print(\"MATH file not found. Using a tiny mock dataset (2 items) for a dry run.\")\n",
    "    return [\n",
    "        {\"qid\": 0, \"question\": \"Compute 7^2 - 4^2.\", \"answer\": r\"\\boxed{33}\"},\n",
    "        {\"qid\": 1, \"question\": \"What is \\\\frac{3}{4} + \\\\frac{5}{6}? Give your answer as a fraction.\", \"answer\": r\"\\boxed{\\frac{19}{12}}\"},\n",
    "    ]\n",
    "\n",
    "# ---------- Prompting ----------\n",
    "def build_math_chat_prompt(tokenizer, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Chat-formatted prompt to elicit one final line as \\\\boxed{...}.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": (\"You are a careful competition mathematician. Solve step by step, \"\n",
    "                     \"then put the final result on the last line as:\\n\\nFinal Answer: {answer}\\n\")},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": (f\"{question}\")}\n",
    "    ]\n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        try:\n",
    "            return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    sys = messages[0][\"content\"]\n",
    "    usr = messages[1][\"content\"]\n",
    "    return f\"<|system|>\\n{sys}\\n<|user|>\\n{usr}\\n<|assistant|>\\n\"\n",
    "\n",
    "# ---------- Generation ----------\n",
    "def answer_batch_unsteered(model, tokenizer, problems: List[str], max_new_tokens=512) -> List[str]:\n",
    "    import torch\n",
    "    outs = []\n",
    "    eos_ids = [tokenizer.eos_token_id]\n",
    "    try:\n",
    "        eot_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "        if isinstance(eot_id, int) and eot_id > 0:\n",
    "            eos_ids.append(eot_id)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for q in problems:\n",
    "            prompt = build_math_chat_prompt(tokenizer, q)\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            gen = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=TEMPERATURE,\n",
    "                top_p=TOP_P,\n",
    "                eos_token_id=eos_ids,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "            text = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
    "            text = text.split(\"Final Answer: {answer}\")[-1]\n",
    "            outs.append(text.strip())\n",
    "    return outs\n",
    "\n",
    "def answer_batch_steered_dw(model, tokenizer, problems: List[str], combined_coefs, alpha: float, max_new_tokens=512) -> List[str]:\n",
    "    outs = []\n",
    "    for q in problems:\n",
    "        prompt = build_math_chat_prompt(tokenizer, q)\n",
    "        res = generate_with_head_intervention_gpu(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            prompts=[prompt],\n",
    "            alpha=alpha,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            combined_coefs=combined_coefs,\n",
    "            return_features=False,\n",
    "            device=model.device if hasattr(model, \"device\") else None,\n",
    "        )\n",
    "        text = res[0][\"answer\"]\n",
    "        text = text.split(\"Final Answer: {answer}\")[-1]\n",
    "        outs.append(text)\n",
    "    return outs\n",
    "\n",
    "# ---------- Eval ----------\n",
    "def evaluate_run(gold: List[str], outputs: List[str]) -> Dict:\n",
    "    preds = [extract_predicted_answer(t) for t in outputs]\n",
    "    correct = [grade_answer(g, p) for g, p in zip(gold, preds)]\n",
    "    for i, t in enumerate(outputs):\n",
    "        print(preds[i], gold[i], correct[i])\n",
    "\n",
    "    df = pd.DataFrame({\"pred\": preds, \"gold\": gold, \"correct\": correct, \"output\": outputs})\n",
    "    df.to_csv(\"./results.csv\")\n",
    "\n",
    "    return {\n",
    "        \"n\": len(gold),\n",
    "        \"correct\": int(sum(correct)),\n",
    "        \"acc\": float(np.mean(correct)) if len(correct) else 0.0,\n",
    "        \"preds\": preds,\n",
    "        \"raw\": outputs,\n",
    "        \"is_correct\": correct,\n",
    "    }\n",
    "\n",
    "# ---------- Experiment ----------\n",
    "def run_math_dw_compare(model_path: str,\n",
    "                        math_records: List[Dict],\n",
    "                        ks: List[int] = K_LIST,\n",
    "                        alphas: List[int] = ALPHAS) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Baseline vs DW-steered evaluation on MATH.\n",
    "    Saves CSV and a simple matplotlib plot under ./results/<model_base>/\n",
    "    \"\"\"\n",
    "    import torch\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer, model = load_tokenizer_and_model(model_path, device=device)\n",
    "    base_name = model_base_name(model_path)\n",
    "\n",
    "    out_dir = os.path.join(\"results\", base_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    questions = [r[\"question\"] for r in math_records]\n",
    "    answers   = [r[\"answer\"]   for r in math_records]\n",
    "\n",
    "    # Load ridge/perf (DW_PREFIX can be 'politician' or 'dw_vote')\n",
    "    print(\"\\n[DW-steering] Loading ridge models & performance...\")\n",
    "    # Use feats shortcut if you have them; else k+performance path works too\n",
    "    try:\n",
    "        feats = load_feats(model_path=model_path, prefix=DW_PREFIX, results_dir=\"./results\", device=device)\n",
    "    except Exception:\n",
    "        feats = None\n",
    "    ridge_models, performance = load_ridge_models(model_path, DW_PREFIX)\n",
    "\n",
    "    rows = []\n",
    "    for k in ks:\n",
    "        print(f\"\\nBuilding combined_coefs for k={k} ...\")\n",
    "        coefs = compute_combined_coefs(\n",
    "            feats=feats,\n",
    "            ridge_models=ridge_models,\n",
    "            k=k,\n",
    "            performance=performance,\n",
    "            device=model.device if hasattr(model, \"device\") else None,\n",
    "        )\n",
    "\n",
    "        for alpha in alphas:\n",
    "            print(f\"[DW] alpha={alpha}, k={k} → generating ...\")\n",
    "            t0 = time.time()\n",
    "            steered_text = answer_batch_steered_dw(\n",
    "                model, tokenizer, questions,\n",
    "                combined_coefs=coefs,\n",
    "                alpha=alpha,\n",
    "                max_new_tokens=MAX_NEW_TOKENS,\n",
    "            )\n",
    "            ev = evaluate_run(answers, steered_text)\n",
    "            dt = time.time() - t0\n",
    "            print(f\"   acc={ev['acc']:.3f} ({ev['correct']}/{ev['n']})  time={dt:.1f}s\")\n",
    "            rows.append({\n",
    "                \"model\": base_name,\n",
    "                \"mode\": \"steered_dw\",\n",
    "                \"alpha\": alpha,\n",
    "                \"k\": k,\n",
    "                \"acc\": ev[\"acc\"],\n",
    "                \"correct\": ev[\"correct\"],\n",
    "                \"n\": ev[\"n\"],\n",
    "            })\n",
    "\n",
    "    # Baseline\n",
    "    print(\"\\n[Baseline] Generating without steering...\")\n",
    "    t0 = time.time()\n",
    "    base_text = answer_batch_unsteered(model, tokenizer, questions, max_new_tokens=MAX_NEW_TOKENS)\n",
    "    base_eval = evaluate_run(answers, base_text)\n",
    "    print(f\"Baseline MATH acc = {base_eval['acc']:.3f} ({base_eval['correct']}/{base_eval['n']})  time={time.time()-t0:.1f}s\")\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": base_name,\n",
    "        \"mode\": \"baseline\",\n",
    "        \"alpha\": 0,\n",
    "        \"k\": 0,\n",
    "        \"acc\": base_eval[\"acc\"],\n",
    "        \"correct\": base_eval[\"correct\"],\n",
    "        \"n\": base_eval[\"n\"],\n",
    "    })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    csv_path = os.path.join(out_dir, \"math_dw_vote_eval.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nSaved summary CSV → {csv_path}\")\n",
    "\n",
    "    # Plot (single figure, default colors)\n",
    "    fig = plt.figure(figsize=(7, 4.5))\n",
    "    plt.axhline(y=base_eval[\"acc\"], linestyle=\"--\", label=f\"Baseline acc = {base_eval['acc']:.3f}\")\n",
    "    for k in sorted(set(df[df[\"mode\"] == \"steered_dw\"][\"k\"])):\n",
    "        sub = df[(df[\"mode\"] == \"steered_dw\") & (df[\"k\"] == k)].sort_values(\"alpha\")\n",
    "        plt.plot(sub[\"alpha\"].tolist(), sub[\"acc\"].tolist(), marker=\"o\", label=f\"Steered (k={k})\")\n",
    "    plt.xlabel(\"alpha (DW-vote steering strength)\")\n",
    "    plt.ylabel(\"MATH accuracy\")\n",
    "    plt.title(f\"MATH: Baseline vs DW-steered • {base_name}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    png_path = os.path.join(out_dir, \"math_dw_vote_eval.png\")\n",
    "    plt.savefig(png_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Saved plot PNG → {png_path}\")\n",
    "\n",
    "    del model\n",
    "    clean_up(device=None)\n",
    "    return df\n",
    "\n",
    "def run_all_models_on_math(models: List[str] = None):\n",
    "    recs = load_math_dataset(MATH_PATHS_TRY)[:LIMIT]\n",
    "    used = models if models is not None else MODELS\n",
    "    outs = []\n",
    "    for m in used:\n",
    "        print(f\"\\n===== Evaluating {m} on MATH =====\")\n",
    "        df = run_math_dw_compare(model_path=m, math_records=recs, ks=K_LIST, alphas=ALPHAS)\n",
    "        outs.append(df.assign(model_path=m))\n",
    "    big = pd.concat(outs, ignore_index=True)\n",
    "    out_csv = \"./results/math_dw_vote_eval_all_models.csv\"\n",
    "    os.makedirs(\"./results\", exist_ok=True)\n",
    "    big.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nWrote combined results: {out_csv}\")\n",
    "    return big\n",
    "\n",
    "# ---------- Example calls ----------\n",
    "# big_df = run_all_models_on_math(MODELS)\n",
    "df_single = run_math_dw_compare(MODELS[1], load_math_dataset(MATH_PATHS_TRY)[:LIMIT], ks=[32, 64], alphas=[-20, -10, 10, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795c0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
